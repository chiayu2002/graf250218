{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u = 0.5, theta = 180.0 度\n",
      "v = 0.25, phi = 60.00000000000001 度\n",
      "球面坐標點: [-0.8660, 0.0000, 0.5000]\n",
      "to_sphere 產生的點的角度: 180.00 度\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.66025404e-01,  1.06057524e-16,  5.00000000e-01])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_sphere(u, v):    #把2維座標轉換成3維笛卡爾座標\n",
    "    # result = u + 0.5\n",
    "    # if result >= 1:\n",
    "    #     result -= 1\n",
    "    theta = 2 * np.pi * u\n",
    "    phi = np.arccos(1 - 2 * v)\n",
    "    cx = np.sin(phi) * np.cos(theta)\n",
    "    cy = np.sin(phi) * np.sin(theta)\n",
    "    cz = np.cos(phi)\n",
    "    s = np.stack([cx, cy, cz])\n",
    "\n",
    "    # 打印調試信息\n",
    "    print(f\"u = {u}, theta = {theta * 180 / np.pi} 度\")\n",
    "    print(f\"v = {v}, phi = {phi * 180 / np.pi} 度\")\n",
    "    print(f\"球面坐標點: [{cx:.4f}, {cy:.4f}, {cz:.4f}]\")\n",
    "    \n",
    "    # 計算該點在 xy 平面的角度\n",
    "    angle = np.arctan2(cy, cx) * 180 / np.pi\n",
    "    print(f\"to_sphere 產生的點的角度: {angle:.2f} 度\")\n",
    "    return s\n",
    "\n",
    "to_sphere(0.5,0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_at(eye, at=np.array([0, 0, 0]), up=np.array([0, 0, 1]), eps=1e-5):   #計算從視點(相機位置)到目標點的視角轉換 相機到世界\n",
    "    at = at.astype(float).reshape(1, 3)\n",
    "    up = up.astype(float).reshape(1, 3)\n",
    "\n",
    "    eye = eye.reshape(-1, 3)\n",
    "    up = up.repeat(eye.shape[0] // up.shape[0], axis=0)\n",
    "    eps = np.array([eps]).reshape(1, 1).repeat(up.shape[0], axis=0)  #形狀為 (up.shape[0], 1)\n",
    "\n",
    "    z_axis = eye - at\n",
    "    z_axis /= np.max(np.stack([np.linalg.norm(z_axis, axis=1, keepdims=True), eps]))  #歸一化\n",
    "\n",
    "    x_axis = np.cross(up, z_axis)\n",
    "    x_axis /= np.max(np.stack([np.linalg.norm(x_axis, axis=1, keepdims=True), eps]))\n",
    "\n",
    "    y_axis = np.cross(z_axis, x_axis)\n",
    "    y_axis /= np.max(np.stack([np.linalg.norm(y_axis, axis=1, keepdims=True), eps]))\n",
    "\n",
    "    r_mat = np.concatenate((x_axis.reshape(-1, 3, 1), y_axis.reshape(-1, 3, 1), z_axis.reshape(-1, 3, 1)), axis=2)\n",
    "\n",
    "    return r_mat  #形狀(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_select_pose(u, v):   #計算旋轉矩陣(相機姿勢)\n",
    "    # sample location on unit sphere\n",
    "    #print(\"Type of self.v:\", type(self.v))\n",
    "    loc = to_sphere(u, v)\n",
    "    # print(\"cx cy cz:\",loc)\n",
    "    # theta = 2 * np.pi * u\n",
    "    # phi = np.arccos(1 - 2 * v)\n",
    "\n",
    "    # print(f\"u: {u}, theta: {theta/np.pi*180.}度\")\n",
    "    # print(f\"v: {v}, phi: {phi/np.pi*180.}度\")\n",
    "    # print(f\"camera position: {loc}\")\n",
    "    \n",
    "    # sample radius if necessary\n",
    "    radius = 3.0\n",
    "    if isinstance(radius, tuple):\n",
    "        radius = np.random.uniform(*radius)\n",
    "\n",
    "    loc = loc * radius\n",
    "    R = look_at(loc)[0]\n",
    "\n",
    "    RT = np.concatenate([R, loc.reshape(3, 1)], axis=1)\n",
    "    RT = torch.Tensor(RT.astype(np.float32))\n",
    "\n",
    "    expected_angle = u * 360\n",
    "    verify_camera_transform(RT, expected_angle)\n",
    "    return RT\n",
    "\n",
    "def verify_camera_transform(c2w, expected_angle):\n",
    "    # 將張量移到 CPU 並轉換為 NumPy\n",
    "    if torch.is_tensor(c2w):\n",
    "        camera_forward = c2w[:3, 2].detach().cpu().numpy()\n",
    "    else:\n",
    "        camera_forward = c2w[:3, 2]\n",
    "    \n",
    "    # 計算實際角度\n",
    "    actual_angle = np.degrees(np.arctan2(camera_forward[1], camera_forward[0]))\n",
    "    if actual_angle < 0:\n",
    "        actual_angle += 360\n",
    "        \n",
    "    print(f\"預期角度: {expected_angle}°\")\n",
    "    print(f\"實際角度: {actual_angle:.2f}°\")\n",
    "    print(f\"相機變換矩陣:\\n{c2w.detach().cpu().numpy() if torch.is_tensor(c2w) else c2w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "u = 0, theta = 0.0 度\n",
      "v = 0.5, phi = 90.0 度\n",
      "球面坐標點: [1.0000, 0.0000, 0.0000]\n",
      "to_sphere 產生的點的角度: 0.00 度\n",
      "預期角度: 0°\n",
      "實際角度: 0.00°\n",
      "相機變換矩陣:\n",
      "[[ 0.0000000e+00 -6.1232343e-17  1.0000000e+00  3.0000000e+00]\n",
      " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  1.0000000e+00  6.1232343e-17  1.8369701e-16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -6.1232e-17,  1.0000e+00,  3.0000e+00],\n",
       "        [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  1.0000e+00,  6.1232e-17,  1.8370e-16]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"===========================\")\n",
    "sample_select_pose(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u = 0, theta = 0.0 度\n",
      "v = 0.5, phi = 90.0 度\n",
      "球面坐標點: [1.0000, 0.0000, 0.0000]\n",
      "to_sphere 產生的點的角度: 0.00 度\n",
      "預期角度: 0°\n",
      "實際角度: 0.00°\n",
      "相機變換矩陣:\n",
      "[[ 0.0000000e+00 -6.1232343e-17  1.0000000e+00  3.0000000e+00]\n",
      " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  1.0000000e+00  6.1232343e-17  1.8369701e-16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3.0000e+00,  0.0000e+00,  1.8370e-16],\n",
       "          [ 3.0000e+00,  0.0000e+00,  1.8370e-16],\n",
       "          [ 3.0000e+00,  0.0000e+00,  1.8370e-16],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  0.0000e+00,  1.8370e-16],\n",
       "          [ 3.0000e+00,  0.0000e+00,  1.8370e-16],\n",
       "          [ 3.0000e+00,  0.0000e+00,  1.8370e-16]],\n",
       " \n",
       "         [[-1.0000e+00, -2.2169e-01,  2.2169e-01],\n",
       "          [-1.0000e+00, -2.1823e-01,  2.2169e-01],\n",
       "          [-1.0000e+00, -2.1477e-01,  2.2169e-01],\n",
       "          ...,\n",
       "          [-1.0000e+00,  2.1130e-01, -2.1823e-01],\n",
       "          [-1.0000e+00,  2.1477e-01, -2.1823e-01],\n",
       "          [-1.0000e+00,  2.1823e-01, -2.1823e-01]]]),\n",
       " tensor([    0,     1,     2,  ..., 16381, 16382, 16383]),\n",
       " tensor([[-0.5000, -0.5000],\n",
       "         [-0.5000, -0.4922],\n",
       "         [-0.5000, -0.4844],\n",
       "         ...,\n",
       "         [ 0.4922,  0.4766],\n",
       "         [ 0.4922,  0.4844],\n",
       "         [ 0.4922,  0.4922]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graf.transforms import FullRaySampler\n",
    "H=W=128\n",
    "fov=25\n",
    "focal = W/2 * 1 / np.tan((.5 * fov * np.pi/180.))\n",
    "def sample_select_rays(u ,v):\n",
    "        pose = sample_select_pose(u, v)\n",
    "        N_samples = 1024  # 例如 32x32=1024\n",
    "        ray_sampler = FullRaySampler(#N_samples=N_samples,\n",
    "                                #      min_scale=0.,\n",
    "                                #      max_scale=1.0,\n",
    "                                #      scale_anneal=0.0001,\n",
    "                                #      random_shift=False, \n",
    "                                #      random_scale=False,\n",
    "                                     orthographic=False)\n",
    "    \n",
    "    # 調用採樣器\n",
    "        batch_rays, select_inds, hw = ray_sampler(H, W, focal, pose)\n",
    "        return batch_rays, select_inds, hw\n",
    "\n",
    "sample_select_rays(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u = 0.0, theta = 0.0 度\n",
      "v = 0.5, phi = 90.0 度\n",
      "球面坐標點: [1.0000, 0.0000, 0.0000]\n",
      "to_sphere 產生的點的角度: 0.00 度\n",
      "預期角度: 0.0°\n",
      "實際角度: 0.00°\n",
      "相機變換矩陣:\n",
      "[[ 0.0000000e+00 -6.1232343e-17  1.0000000e+00  3.0000000e+00]\n",
      " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  1.0000000e+00  6.1232343e-17  1.8369701e-16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]],\n",
       " \n",
       "         [[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]],\n",
       " \n",
       "         [[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]],\n",
       " \n",
       "         [[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]],\n",
       " \n",
       "         [[3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          ...,\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16],\n",
       "          [3.0000e+00, 0.0000e+00, 1.8370e-16]]]),\n",
       " tensor([[[-1.0000, -0.2217,  0.2217],\n",
       "          [-1.0000, -0.2182,  0.2217],\n",
       "          [-1.0000, -0.2148,  0.2217],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113,  0.2217],\n",
       "          [-1.0000,  0.2148,  0.2217],\n",
       "          [-1.0000,  0.2182,  0.2217]],\n",
       " \n",
       "         [[-1.0000, -0.2217,  0.2182],\n",
       "          [-1.0000, -0.2182,  0.2182],\n",
       "          [-1.0000, -0.2148,  0.2182],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113,  0.2182],\n",
       "          [-1.0000,  0.2148,  0.2182],\n",
       "          [-1.0000,  0.2182,  0.2182]],\n",
       " \n",
       "         [[-1.0000, -0.2217,  0.2148],\n",
       "          [-1.0000, -0.2182,  0.2148],\n",
       "          [-1.0000, -0.2148,  0.2148],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113,  0.2148],\n",
       "          [-1.0000,  0.2148,  0.2148],\n",
       "          [-1.0000,  0.2182,  0.2148]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.0000, -0.2217, -0.2113],\n",
       "          [-1.0000, -0.2182, -0.2113],\n",
       "          [-1.0000, -0.2148, -0.2113],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113, -0.2113],\n",
       "          [-1.0000,  0.2148, -0.2113],\n",
       "          [-1.0000,  0.2182, -0.2113]],\n",
       " \n",
       "         [[-1.0000, -0.2217, -0.2148],\n",
       "          [-1.0000, -0.2182, -0.2148],\n",
       "          [-1.0000, -0.2148, -0.2148],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113, -0.2148],\n",
       "          [-1.0000,  0.2148, -0.2148],\n",
       "          [-1.0000,  0.2182, -0.2148]],\n",
       " \n",
       "         [[-1.0000, -0.2217, -0.2182],\n",
       "          [-1.0000, -0.2182, -0.2182],\n",
       "          [-1.0000, -0.2148, -0.2182],\n",
       "          ...,\n",
       "          [-1.0000,  0.2113, -0.2182],\n",
       "          [-1.0000,  0.2148, -0.2182],\n",
       "          [-1.0000,  0.2182, -0.2182]]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=0.\n",
    "v=0.5\n",
    "pose = sample_select_pose(u, v)\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))  # pytorch's meshgrid has indexing='ij'\n",
    "    i = i.t()\n",
    "    j = j.t()\n",
    "    x = (i-W*.5)/focal\n",
    "    y = -(j-H*.5)/focal\n",
    "    z = -torch.ones_like(i)\n",
    "\n",
    "    dirs = torch.stack([x, y, z], -1)\n",
    "    # Rotate ray directions from camera frame to the world frame\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape) #torch.Size([128, 128, 3])\n",
    "    \n",
    "    return rays_o, rays_d\n",
    "\n",
    "get_rays(H,W, focal, pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_render_poses(radius, angle_range=(0, 360), theta=0, N=40, swap_angles=False):   #用在eval的時候\n",
    "    poses = []\n",
    "    theta = max(0.1, theta)\n",
    "    for angle in np.linspace(angle_range[0],angle_range[1],N+1)[:-1]:\n",
    "        angle = max(0.1, angle)\n",
    "        if swap_angles:\n",
    "            loc = polar_to_cartesian(radius, theta, angle, deg=True)\n",
    "        else:\n",
    "            loc = polar_to_cartesian(radius, angle, theta, deg=True)\n",
    "        R = look_at(loc)[0]\n",
    "        RT = np.concatenate([R, loc.reshape(3, 1)], axis=1)\n",
    "        poses.append(RT)\n",
    "    return torch.from_numpy(np.stack(poses))\n",
    "\n",
    "def polar_to_cartesian(r, theta, phi, deg=True): #極座標到笛卡爾座標\n",
    "\n",
    "    if deg:\n",
    "        phi = phi * np.pi / 180\n",
    "        theta = theta * np.pi / 180\n",
    "    cx = np.sin(phi) * np.cos(theta)\n",
    "    cy = np.sin(phi) * np.sin(theta)\n",
    "    cz = np.cos(phi)\n",
    "    print(f\"test球面坐標點: [{cx:.4f}, {cy:.4f}, {cz:.4f}]\")\n",
    "    return r * np.stack([cx, cy, cz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test球面坐標點: [1.0000, 0.0017, 0.0000]\n"
     ]
    }
   ],
   "source": [
    "c2w = get_render_poses(3, angle_range=(0, 90), theta=90, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))  # pytorch's meshgrid has indexing='ij'\n",
    "    i = i.t()\n",
    "    j = j.t()\n",
    "    x = (i-W*.5)/focal\n",
    "    y = -(j-H*.5)/focal\n",
    "    z = -torch.ones_like(i)\n",
    "\n",
    "    dirs = torch.stack([x, y, z], -1)\n",
    "    # Rotate ray directions from camera frame to the world frame\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape) #torch.Size([128, 128, 3])\n",
    "\n",
    "    # 在這裡直接驗證射線方向\n",
    "    rays_d_cpu = rays_d.detach().cpu()\n",
    "    \n",
    "    # 檢查中心射線的方向\n",
    "    def calculate_ray_angle(ray):\n",
    "        return np.degrees(np.arctan2(ray[0], -ray[2]))\n",
    "    \n",
    "    # 檢查射線分布\n",
    "    center_ray = rays_d_cpu[H//2, W//2]\n",
    "    left_ray = rays_d_cpu[H//2, 0]\n",
    "    right_ray = rays_d_cpu[H//2, -1]\n",
    "    \n",
    "    # print(f\"左邊 x/z: {(-W/2/focal):.4f}\")\n",
    "    # print(f\"右邊 x/z: {(W/2/focal):.4f}\")\n",
    "    # print(f\"中心射線角度: {calculate_ray_angle(center_ray):.2f}°\")\n",
    "    # print(f\"左邊射線角度: {calculate_ray_angle(left_ray):.2f}°\")\n",
    "    # print(f\"右邊射線角度: {calculate_ray_angle(right_ray):.2f}°\")\n",
    "    \n",
    "    return rays_o, rays_d\n",
    "\n",
    "W = H = 128\n",
    "fov = 25\n",
    "focal = W/2 * 1 / np.tan((.5 * fov * np.pi/180.))\n",
    "ray_0, ray_d = get_rays(W, H, focal, c2w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9996, -0.2234,  0.2217],\n",
       "         [-0.9996, -0.2200,  0.2217],\n",
       "         [-0.9996, -0.2165,  0.2217],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096,  0.2217],\n",
       "         [-1.0004,  0.2130,  0.2217],\n",
       "         [-1.0004,  0.2165,  0.2217]],\n",
       "\n",
       "        [[-0.9996, -0.2234,  0.2182],\n",
       "         [-0.9996, -0.2200,  0.2182],\n",
       "         [-0.9996, -0.2165,  0.2182],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096,  0.2182],\n",
       "         [-1.0004,  0.2130,  0.2182],\n",
       "         [-1.0004,  0.2165,  0.2182]],\n",
       "\n",
       "        [[-0.9996, -0.2234,  0.2148],\n",
       "         [-0.9996, -0.2200,  0.2148],\n",
       "         [-0.9996, -0.2165,  0.2148],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096,  0.2148],\n",
       "         [-1.0004,  0.2130,  0.2148],\n",
       "         [-1.0004,  0.2165,  0.2148]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9996, -0.2234, -0.2113],\n",
       "         [-0.9996, -0.2200, -0.2113],\n",
       "         [-0.9996, -0.2165, -0.2113],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096, -0.2113],\n",
       "         [-1.0004,  0.2130, -0.2113],\n",
       "         [-1.0004,  0.2165, -0.2113]],\n",
       "\n",
       "        [[-0.9996, -0.2234, -0.2148],\n",
       "         [-0.9996, -0.2200, -0.2148],\n",
       "         [-0.9996, -0.2165, -0.2148],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096, -0.2148],\n",
       "         [-1.0004,  0.2130, -0.2148],\n",
       "         [-1.0004,  0.2165, -0.2148]],\n",
       "\n",
       "        [[-0.9996, -0.2234, -0.2182],\n",
       "         [-0.9996, -0.2200, -0.2182],\n",
       "         [-0.9996, -0.2165, -0.2182],\n",
       "         ...,\n",
       "         [-1.0004,  0.2096, -0.2182],\n",
       "         [-1.0004,  0.2130, -0.2182],\n",
       "         [-1.0004,  0.2165, -0.2182]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = look_at(loc)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT = sample_select_pose(3, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70710571, 0.00123413, 0.70710678])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=[-0.00174533,  0.99999848,  0.        ]\n",
    "q=[-0.7071057 , -0.00123413,  0.70710678]\n",
    "np.cross(z,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2246e-16,  6.1232e-17, -1.0000e+00, -3.0000e+00],\n",
       "        [-1.0000e+00, -7.4988e-33,  1.2246e-16,  3.6739e-16],\n",
       "        [ 0.0000e+00,  1.0000e+00,  6.1232e-17,  1.8370e-16]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0000000e+00,  1.2246468e-16,  6.1232340e-17])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sphere(0.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_to_cartesian(r, theta, phi, deg=True): #極座標到笛卡爾座標\n",
    "\n",
    "    if deg:\n",
    "        phi = phi * np.pi / 180\n",
    "        theta = theta * np.pi / 180\n",
    "    cx = np.sin(phi) * np.cos(theta)\n",
    "    cy = np.sin(phi) * np.sin(theta)\n",
    "    cz = np.cos(phi)\n",
    "    return r * np.stack([cx, cy, cz])\n",
    "\n",
    "def get_render_poses(radius, angle_range=(0, 360), theta=0, N=40, swap_angles=False):   #用在eval的時候\n",
    "    poses = []\n",
    "    for angle in np.linspace(angle_range[0],angle_range[1],N+1)[:-1]:\n",
    "        if swap_angles:\n",
    "            loc = polar_to_cartesian(radius, theta, angle, deg=True)\n",
    "        else:\n",
    "            loc = polar_to_cartesian(radius, angle, theta, deg=True)\n",
    "\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_radius = 3.0\n",
    "\n",
    "def get_render_poses_by_angles(render_radius, azimuth, elevation, N_poses=1):\n",
    "    \"\"\"Compute equidistant render poses varying azimuth and polar angle, respectively.\"\"\"\n",
    "    # theta = to_theta(u)\n",
    "    # phi = to_phi(v)\n",
    "    angle_range = (azimuth, azimuth)\n",
    "\n",
    "    loc = get_render_poses(render_radius, angle_range=angle_range, theta=elevation, N=N_poses)\n",
    "\n",
    "    return  loc\n",
    "\n",
    "angle_positions = [\n",
    "    (0., 90.),    # 正面 (0度方位角，90度仰角)\n",
    "    (45., 90.),   # 右前45度\n",
    "    (90., 90.),   # 右側\n",
    "    (135., 90.),  # 右後45度\n",
    "    (180., 90.),  # 背面\n",
    "    (225., 90.),    # 俯視30度 (90-30=60)\n",
    "    (270., 90.),   # 仰視30度 (90+30=120)\n",
    "    (315., 90.),  # 左前45度\n",
    "]\n",
    "\n",
    "loc_list = []\n",
    "for i, (azimuth, elevation) in enumerate(angle_positions):\n",
    "    loc = get_render_poses_by_angles(render_radius, azimuth, elevation)\n",
    "    loc_list.append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 90.0) [3.0000000e+00 0.0000000e+00 1.8369702e-16]\n",
      "(45.0, 90.0) [2.12132034e+00 2.12132034e+00 1.83697020e-16]\n",
      "(90.0, 90.0) [1.8369702e-16 3.0000000e+00 1.8369702e-16]\n",
      "(135.0, 90.0) [-2.12132034e+00  2.12132034e+00  1.83697020e-16]\n",
      "(180.0, 90.0) [-3.0000000e+00  3.6739404e-16  1.8369702e-16]\n",
      "(225.0, 90.0) [-2.12132034e+00 -2.12132034e+00  1.83697020e-16]\n",
      "(270.0, 90.0) [-5.5109106e-16 -3.0000000e+00  1.8369702e-16]\n",
      "(315.0, 90.0) [ 2.12132034e+00 -2.12132034e+00  1.83697020e-16]\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(angle_positions, loc_list):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = [[ 0.9975641,  -0.02325215,  0.06576703,  0.19730112],\n",
    " [ 0.06975647,  0.33252123, -0.9405125,  -2.8215373 ],\n",
    " [-0.,          0.9428091,   0.3333332,   0.9999996 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graftest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
